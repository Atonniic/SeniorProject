{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c2839a5-4bdb-4fe3-847c-520daace3eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff9fcb12-5bbb-486e-ab64-e91ebe55fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and combine training datasets\n",
    "train_data_part1 = pd.read_csv('TrainData01.csv')\n",
    "train_data_part2 = pd.read_csv('TrainData02.csv')\n",
    "train_data = pd.concat([train_data_part1, train_data_part2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5eff4d-ee46-4a1c-965e-919f7200401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "test_data = pd.read_csv('TestData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98e404c-6a46-4f05-ad14-975a82809c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels for train and test data\n",
    "X_train = train_data[['subject', 'email_to', 'email_from','cleanMessage']]\n",
    "y_train = train_data['label']\n",
    "X_test = test_data[['subject', 'email_to', 'email_from','cleanMessage']]\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a2f19f-ddb9-49d3-80ff-5d5e9a4868e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text fields (subject, email_to, email_from, cleanMessage) into a single field for vectorization\n",
    "X_train.loc[:, 'text'] = X_train['subject'] + ' ' + X_train['email_to'] + ' ' + X_train['email_from'] + ' ' + X_train['cleanMessage']\n",
    "X_test.loc[:, 'text'] = X_test['subject'] + ' ' + X_test['email_to'] + ' ' + X_test['email_from'] + ' ' + X_test['cleanMessage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b3a09de-2b02-4033-a8ad-ea70d65dee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with an empty string using .loc\n",
    "X_train.loc[:, 'text'] = X_train['text'].fillna('')\n",
    "X_test.loc[:, 'text'] = X_test['text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06987f02-b53a-4dd3-86db-c26f868e7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['text'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dcb98fb-4847-4721-b335-a4be9d6cbe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e639887-6bad-47a9-a377-b760516ca061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    \n",
    "    return training_time, accuracy, recall, precision, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "514a6bd3-7e20-4104-85e4-cc7dc0dd6145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_results = evaluate_model(nb_model, X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "results['Naive Bayes'] = nb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42f2540d-f2de-4b25-ad0a-3ca44022a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_results = evaluate_model(dt_model, X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "results['Decision Tree'] = dt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "581d90bf-2714-45cd-a05e-556e1617256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_results = evaluate_model(rf_model, X_train_tfidf, y_train, X_test_tfidf, y_test)\n",
    "results['Random Forest'] = rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8c09317-d0ae-4066-b2f3-8e9b0ed46233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Naive Bayes\n",
      "Training Time: 0.0545 seconds\n",
      "Accuracy: 0.9514\n",
      "Recall: 0.9101\n",
      "Precision: 0.9921\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      7566\n",
      "           1       0.99      0.91      0.95      7566\n",
      "\n",
      "    accuracy                           0.95     15132\n",
      "   macro avg       0.95      0.95      0.95     15132\n",
      "weighted avg       0.95      0.95      0.95     15132\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7511   55]\n",
      " [ 680 6886]]\n",
      "\n",
      "Model: Decision Tree\n",
      "Training Time: 17.9777 seconds\n",
      "Accuracy: 0.9933\n",
      "Recall: 0.9938\n",
      "Precision: 0.9929\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      7566\n",
      "           1       0.99      0.99      0.99      7566\n",
      "\n",
      "    accuracy                           0.99     15132\n",
      "   macro avg       0.99      0.99      0.99     15132\n",
      "weighted avg       0.99      0.99      0.99     15132\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7512   54]\n",
      " [  47 7519]]\n",
      "\n",
      "Model: Random Forest\n",
      "Training Time: 60.9882 seconds\n",
      "Accuracy: 0.9952\n",
      "Recall: 0.9966\n",
      "Precision: 0.9938\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      7566\n",
      "           1       0.99      1.00      1.00      7566\n",
      "\n",
      "    accuracy                           1.00     15132\n",
      "   macro avg       1.00      1.00      1.00     15132\n",
      "weighted avg       1.00      1.00      1.00     15132\n",
      "\n",
      "Confusion Matrix:\n",
      "[[7519   47]\n",
      " [  26 7540]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "for model_name, result in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Training Time: {result[0]:.4f} seconds\")\n",
    "    print(f\"Accuracy: {result[1]:.4f}\")\n",
    "    print(f\"Recall: {result[2]:.4f}\")\n",
    "    print(f\"Precision: {result[3]:.4f}\")\n",
    "    print(f\"Classification Report:\\n{classification_report(y_test, result[4])}\")\n",
    "    print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, result[4])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69815a00-6db2-4620-8902-b53299d58477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
